{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_image_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4sdMBzNwON6TNXn3HKQ4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udupa-varun/pyimagesearch_uni/blob/main/deep_learning/101/first_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGJ2EgWeMsgr",
        "outputId": "8316c69f-911c-44bd-9e4b-8d308d8a9453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 12:45:52--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/first-image-classifier/first-image-classifier.zip\n",
            "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.218.243.113\n",
            "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.218.243.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 196971354 (188M) [application/zip]\n",
            "Saving to: ‘first-image-classifier.zip’\n",
            "\n",
            "first-image-classif 100%[===================>] 187.85M  21.2MB/s    in 9.6s    \n",
            "\n",
            "2022-06-07 12:46:02 (19.5 MB/s) - ‘first-image-classifier.zip’ saved [196971354/196971354]\n",
            "\n",
            "/content/first-image-classifier\n"
          ]
        }
      ],
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/first-image-classifier/first-image-classifier.zip\n",
        "!unzip -qq first-image-classifier.zip\n",
        "%cd first-image-classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "SFmoCMWnMxrn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePreprocessor:\n",
        "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.inter = inter\n",
        "\n",
        "    def preprocess(self, image):\n",
        "        # resize image to a fixed size, ignoring aspect ratio\n",
        "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
      ],
      "metadata": {
        "id": "uxmGX4T0NARG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDatasetLoader:\n",
        "    def __init__(self, preprocessors=None):\n",
        "        # store the image preprocessor\n",
        "        self.preprocessors = preprocessors\n",
        "\n",
        "        # if the preprocessors are None, initialize them as an\n",
        "        # empty list\n",
        "        if self.preprocessors is None:\n",
        "            self.preprocessors = []\n",
        "\n",
        "    def load(self, image_paths, verbose=-1):\n",
        "        # initialize the list of features and labels\n",
        "        data = []\n",
        "        labels = []\n",
        "\n",
        "        # loop over the input images\n",
        "        for (i, image_path) in enumerate(image_paths):\n",
        "            # load the image and extract the class label assuming\n",
        "            # that our path has the following format:\n",
        "            # /path/to/dataset/{class}/{image}.jpg\n",
        "            image = cv2.imread(image_path)\n",
        "            label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "            # check to see if our preprocessors are not None\n",
        "            if self.preprocessors is not None:\n",
        "                # loop over the preprocessors and apply each to\n",
        "                # the image\n",
        "                for p in self.preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "            # treat our processed image as a \"feature vector\"\n",
        "            # by updating the data list followed by the labels\n",
        "            data.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "            # show an update every `verbose` images\n",
        "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "                print(f\"[INFO] processed {i + 1}/{len(image_paths)}\")\n",
        "\n",
        "        # return a tuple of the data and labels\n",
        "        return (np.array(data), np.array(labels))"
      ],
      "metadata": {
        "id": "mI6_QQexNdJz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "#\thelp=\"path to input dataset\")\n",
        "#ap.add_argument(\"-k\", \"--neighbors\", type=int, default=1,\n",
        "#\thelp=\"# of nearest neighbors for classification\")\n",
        "#ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1,\n",
        "#\thelp=\"# of jobs for k-NN distance (-1 uses all available cores)\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"dataset\": \"dataset/animals\",\n",
        "    \"neighbors\": 1,\n",
        "    \"jobs\": -1\n",
        "}"
      ],
      "metadata": {
        "id": "Fl11X32IOBHv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab list of images to describe\n",
        "print(\"[INFO] loading images...\")\n",
        "image_paths = list(paths.list_images(args[\"dataset\"]))\n",
        "\n",
        "# init image preprocessor\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
        "# load dataset and reshape data matrix\n",
        "(data, labels) = sdl.load(image_paths, verbose=500)\n",
        "data = data.reshape((data.shape[0], 3072))\n",
        "\n",
        "# show memory consumption of the images\n",
        "mem_usage = data.nbytes / (1024 * 1024.0)\n",
        "print(f\"[INFO] features matrix: {mem_usage:.1f}MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t8DFzqdOEsQ",
        "outputId": "7d3ed75d-40bf-4a6a-fb1f-2d8f28ca94a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] processed 500/3000\n",
            "[INFO] processed 1000/3000\n",
            "[INFO] processed 1500/3000\n",
            "[INFO] processed 2000/3000\n",
            "[INFO] processed 2500/3000\n",
            "[INFO] processed 3000/3000\n",
            "[INFO] features matrix: 8.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode labels as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# partition the data into train/test splits (75/25)\n",
        "(train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "3MP8CXBkO8uH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate a k-NN classifier on raw pixel intensities\n",
        "print(\"[INFO] evaluating a k-NN classifier...\")\n",
        "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"], n_jobs=args[\"jobs\"])\n",
        "model.fit(train_x, train_y)\n",
        "print(classification_report(test_y, model.predict(test_x), target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEpsy-QCPa2N",
        "outputId": "ae08924d-bbc9-44b8-d4c9-ea79073af49b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating a k-NN classifier...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.39      0.49      0.44       239\n",
            "        dogs       0.37      0.46      0.41       249\n",
            "       panda       0.78      0.41      0.54       262\n",
            "\n",
            "    accuracy                           0.45       750\n",
            "   macro avg       0.51      0.45      0.46       750\n",
            "weighted avg       0.52      0.45      0.46       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Your First Image Classifier: Using k-NN to Classify Images*](https://www.pyimagesearch.com/2021/04/17/your-first-image-classifier-using-k-nn-to-classify-images/) published on 2021-04-17."
      ],
      "metadata": {
        "id": "BUwXSIBwP4J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m8y7IcBfP8Ju"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}